{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QCB455/COS551 Final Project Pretraining Loss Visualization\n",
    "# Author: Supraj Gunda\n",
    "\n",
    "# The image that this file produces is shown in the directory as \"pretrain_loss.png\".\n",
    "# The image is not finalized, but it shows work towards visualizing such a metric.\n",
    "# The reason it is not finalized is because the regex from the slurm.out files produced by the cluster are not consistent.\n",
    "# Furthermore, we thought that the analysis/visualizations we produced were already sufficient.\n",
    "\n",
    "from glob import glob\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build on Colin's extract metrics method to produce .out files representing the cluster finetuning jobs\n",
    "\n",
    "def extract_metrics(file):\n",
    "    best_val_loss = None\n",
    "    d_model = None\n",
    "    n_layer = None\n",
    "    bed_file = None\n",
    "    fasta_file = None\n",
    "    max_epochs = None\n",
    "    current_epoch = None\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if 'd_model' in line:\n",
    "                match = re.search(r'd_model:\\s*(\\d+)', line)\n",
    "                if match:\n",
    "                    d_model = int(match.group(1))\n",
    "            elif 'n_layer' in line:\n",
    "                match = re.search(r'n_layer:\\s*(\\d+)', line)\n",
    "                if match:\n",
    "                    n_layer = int(match.group(1))\n",
    "            elif 'bed_file' in line:\n",
    "                match = re.search(r'bed_file:\\s*(\\S+)', line)\n",
    "                if match:\n",
    "                    bed_file = match.group(1)\n",
    "            elif 'fasta_file' in line:\n",
    "                match = re.search(r'fasta_file:\\s*(\\S+)', line)\n",
    "                if match:\n",
    "                    fasta_file = match.group(1)\n",
    "            elif 'max_epochs' in line:\n",
    "                match = re.search(r'max_epochs:\\s*(\\d+)', line)\n",
    "                if match:\n",
    "                    max_epochs = int(match.group(1))\n",
    "            elif 'best' in line:\n",
    "                match = re.search(r'(?<=best )\\d+\\.\\d+', line)\n",
    "                if match:\n",
    "                    curr_best = float(match.group(0))\n",
    "                    if best_val_loss is None or curr_best < best_val_loss:\n",
    "                        best_val_loss = curr_best\n",
    "            elif 'Epoch' in line:\n",
    "                match = re.search(r'Epoch\\s+(\\d+)', line)\n",
    "                if match:\n",
    "                    epoch = int(match.group(1))\n",
    "                    if current_epoch is None or epoch > current_epoch:\n",
    "                        current_epoch = epoch\n",
    "\n",
    "        print(f'Width: {d_model}')\n",
    "        print(f'Depth: {n_layer}')\n",
    "        print(f'Bed file: {bed_file}')\n",
    "        print(f'Fasta file: {fasta_file}')\n",
    "        print(f'Max epochs: {max_epochs}')\n",
    "        print(f'Epoch {current_epoch}')\n",
    "        \n",
    "        if best_val_loss is not None:\n",
    "            ppl = np.exp(best_val_loss)\n",
    "            print(f'PPL: {ppl}')\n",
    "        else:\n",
    "            ppl = None\n",
    "\n",
    "        return d_model, n_layer, bed_file, fasta_file, max_epochs, ppl\n",
    "\n",
    "directory = '/scratch/gpfs/sg0666/hyena-dna/slurm_pretrain'\n",
    "files = glob(f'{directory}/*.out')\n",
    "\n",
    "for file in files:\n",
    "    extract_metrics(file)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads all of the .out files previously made\n",
    "\n",
    "# results of the experiments\n",
    "results = []\n",
    "\n",
    "directory = '/Users/Supraj1/qcb455/loss/slurm_files/slurm_pretrain'\n",
    "\n",
    "# all files named something.out\n",
    "files = glob(f'{directory}/*.out')\n",
    "\n",
    "for file in files:\n",
    "    metrics = extract_metrics(file)\n",
    "    print(f\"File: {file}\")\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    results.append(metrics)\n",
    "\n",
    "\n",
    "# save this information to a CSV file\n",
    "output_csv = 'metrics_summary_PT.csv'\n",
    "header = ['d_model', 'n_layer', 'bed_file', 'fasta_file', 'max_epochs', 'PPL']\n",
    "\n",
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex (regular expression) algorithm to get the epoch losses\n",
    "def extractLosses(file_path):\n",
    "    trainLosses = []\n",
    "    valLosses = []\n",
    "\n",
    "    # read the .out file\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    currEpoch = None\n",
    "    lastTrainLoss = None\n",
    "    lastValLoss = None\n",
    "\n",
    "    for line in lines:\n",
    "        # if you find epoch with epoch loss, hold the value\n",
    "        epochMatch = re.search(r\"Epoch (\\d+):\", line)\n",
    "        if epochMatch:\n",
    "            epoch = int(epochMatch.group(1))\n",
    "\n",
    "            # if moving to a different epoch, save the last losses\n",
    "            if currEpoch is not None and currEpoch != epoch:\n",
    "                trainLosses.append(lastTrainLoss)\n",
    "                valLosses.append(lastValLoss)\n",
    "\n",
    "            # update the current epoch\n",
    "            currEpoch = epoch\n",
    "            lastTrainLoss = None  # Reset train loss\n",
    "            lastValLoss = None    # Reset validation loss\n",
    "\n",
    "        # hold training loss if found\n",
    "        trainLossMatch = re.search(r\"loss=([\\d.]+)\", line)\n",
    "        if trainLossMatch:\n",
    "            lastTrainLoss = float(trainLossMatch.group(1))\n",
    "\n",
    "        # hold validation loss if found\n",
    "        valLossMatch = re.search(r\"val/loss=([\\d.]+)\", line)\n",
    "        if valLossMatch:\n",
    "            lastValLoss = float(valLossMatch.group(1))\n",
    "\n",
    "    # for final epoch\n",
    "    if currEpoch is not None:\n",
    "        trainLosses.append(lastTrainLoss)\n",
    "        valLosses.append(lastValLoss)\n",
    "\n",
    "    return trainLosses, valLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/Users/Supraj1/qcb455/loss/slurm_files/slurm_pretrain'\n",
    "\n",
    "# to get all files with .out suffix\n",
    "filePaths = glob(f'{dir}/*.out')\n",
    "# start at index 1 instead of 0\n",
    "fileNames = [f\"File {i + 1}\" for i in range(len(filePaths))]\n",
    "\n",
    "# plotting\n",
    "# this is number of rows\n",
    "rows = (len(filePaths) + 1) // 2  \n",
    "\n",
    "fig, axes = plt.subplots(rows, 2, figsize=(10, rows * 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(filePaths)):\n",
    "    filePath = filePaths[i]\n",
    "    fileName = fileNames[i]\n",
    "    trainLosses, valLosses = extractLosses(filePath)\n",
    "\n",
    "    # check if extracted properly\n",
    "    if not trainLosses:\n",
    "        print(f\"No epoch-level train losses found in {filePath}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # check that both lists have the same length\n",
    "    epochs = list(range(1, len(trainLosses) + 1))\n",
    "\n",
    "    # plot\n",
    "    ax = axes[i]\n",
    "    \n",
    "    ax.plot(epochs, trainLosses, label=\"Train Loss\", color=\"blue\")\n",
    "    if valLosses:\n",
    "        ax.plot(epochs, valLosses, label=\"Val Loss\", color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "    ax.set_title(fileName)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
